#!/usr/bin/env python3
"""
Batch CTS Retrieval System
===========================
Systematically retrieves all works from Scaife CTS API.

Strategy:
1. Load CTS URN catalog
2. For each work, discover available passages via CTS GetValidReff
3. Batch retrieve all passages
4. Save with full provenance

NO HALLUCINATION - Only verified CTS texts.
"""

import requests
import time
from xml.etree import ElementTree as ET
import json
from typing import Dict, List, Optional
from pathlib import Path
import sys

class BatchCTSRetriever:
    """Batch retrieve multiple works via Scaife CTS API"""

    BASE_URL = "https://scaife.perseus.org/library"
    TEI_NS = {'tei': 'http://www.tei-c.org/ns/1.0'}

    def __init__(self, delay=0.3, output_dir='retrieved_texts/scaife_cts'):
        self.delay = delay
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Academic Research - Ancient Free Will Database'
        })
        self.stats = {
            'works_attempted': 0,
            'works_succeeded': 0,
            'passages_retrieved': 0,
            'passages_failed': 0,
        }

    def retrieve_passage(self, urn: str) -> Optional[str]:
        """Retrieve single passage"""
        api_url = f"{self.BASE_URL}/{urn}/cts-api-xml/"

        try:
            response = self.session.get(api_url, timeout=15)
            response.raise_for_status()

            root = ET.fromstring(response.content)

            text_parts = []
            for selector in ['.//tei:p', './/tei:div', './/tei:l', './/tei:ab']:
                elements = root.findall(selector, self.TEI_NS)
                if elements:
                    for elem in elements:
                        text = ''.join(elem.itertext()).strip()
                        if text:
                            text_parts.append(text)
                    break

            if not text_parts:
                text_parts = [''.join(root.itertext()).strip()]

            return ' '.join(text_parts).strip() if text_parts else None

        except Exception as e:
            return None

    def retrieve_work_sections(self, urn_base: str, sections: List) -> Dict:
        """Retrieve work by known sections"""
        results = {}
        success = 0
        failed = []

        for section in sections:
            urn = f"{urn_base}:{section}"
            sys.stdout.write(f"  {section:>10} ")
            sys.stdout.flush()

            text = self.retrieve_passage(urn)
            time.sleep(self.delay)

            if text:
                results[str(section)] = {
                    'urn': urn,
                    'text': text,
                    'url': f"{self.BASE_URL}/{urn}/",
                }
                success += 1
                self.stats['passages_retrieved'] += 1
                print(f"‚úì ({len(text):5d} chars)")
            else:
                failed.append(section)
                self.stats['passages_failed'] += 1
                print("‚úó")

        return results, success, failed

    def retrieve_work(self, work_name: str, urn_base: str, sections: List = None,
                     author: str = '', language: str = '') -> Dict:
        """Retrieve complete work"""
        print(f"\n{'='*80}")
        print(f"RETRIEVING: {author}, {work_name}")
        print(f"CTS URN: {urn_base}")
        print(f"{'='*80}")

        self.stats['works_attempted'] += 1

        # If no sections provided, try standard ranges
        if not sections:
            print("\n‚ö†Ô∏è  No sections specified - trying default range 1-50...")
            sections = list(range(1, 51))

        print(f"\nRetrieving {len(sections)} sections...")
        print("-"*80)

        passages, success, failed = self.retrieve_work_sections(urn_base, sections)

        # Build work data
        work_data = {
            'metadata': {
                'work': work_name,
                'author': author,
                'language': language,
                'urn_base': urn_base,
                'source': 'Scaife Viewer CTS API',
                'protocol': 'Canonical Text Services (CTS)',
                'format': 'TEI-XML',
                'retrieved_date': '2025-10-25',
                'sections_retrieved': success,
                'sections_failed': failed,
                'verification_status': 'cts_verified'
            },
            'passages': passages
        }

        # Save
        safe_name = work_name.lower().replace(' ', '_').replace(',', '')
        filename = self.output_dir / f"{safe_name}_cts.json"

        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(work_data, f, indent=2, ensure_ascii=False)

        print(f"\n{'='*80}")
        print(f"‚úì Retrieved {success}/{len(sections)} sections")
        if failed and len(failed) < 20:
            print(f"‚úó Failed: {failed[:10]}{'...' if len(failed) > 10 else ''}")
        print(f"‚úì Saved to: {filename}")
        print(f"{'='*80}\n")

        if success > 0:
            self.stats['works_succeeded'] += 1

        return work_data

    def print_stats(self):
        """Print retrieval statistics"""
        print("\n" + "="*80)
        print("BATCH RETRIEVAL STATISTICS")
        print("="*80)
        print(f"Works attempted: {self.stats['works_attempted']}")
        print(f"Works succeeded: {self.stats['works_succeeded']}")
        print(f"Passages retrieved: {self.stats['passages_retrieved']}")
        print(f"Passages failed: {self.stats['passages_failed']}")
        print(f"Success rate: {self.stats['passages_retrieved']/(self.stats['passages_retrieved']+self.stats['passages_failed'])*100:.1f}%")
        print("="*80)


def main():
    """Batch retrieve top priority works"""
    retriever = BatchCTSRetriever(delay=0.3)

    print("\n" + "="*80)
    print("BATCH CTS RETRIEVAL - ANCIENT FREE WILL DATABASE")
    print("="*80)
    print("\nRetrieving top 11 most-cited works...")

    # Priority queue
    works = [
        # Already done:
        # {'name': 'De Fato', 'urn': 'urn:cts:latinLit:phi0474.phi054.perseus-lat1',
        #  'sections': range(1, 49), 'author': 'Cicero', 'lang': 'Latin', 'cites': 83},

        {'name': 'Nicomachean Ethics', 'urn': 'urn:cts:greekLit:tlg0086.tlg010.perseus-grc1',
         'sections': None, 'author': 'Aristotle', 'lang': 'Greek', 'cites': 38},

        {'name': 'De Fato', 'urn': 'urn:cts:greekLit:tlg0085.tlg014.perseus-grc1',
         'sections': range(1, 36), 'author': 'Alexander of Aphrodisias', 'lang': 'Greek', 'cites': 35},

        {'name': 'Noctes Atticae', 'urn': 'urn:cts:latinLit:phi1254.phi001.perseus-lat1',
         'sections': None, 'author': 'Aulus Gellius', 'lang': 'Latin', 'cites': 27},

        # Lucretius already done via old Perseus
        # {'name': 'De Rerum Natura', 'urn': 'urn:cts:latinLit:phi0550.phi001.perseus-lat1',
        #  'sections': None, 'author': 'Lucretius', 'lang': 'Latin', 'cites': 24},

        {'name': 'Enneads', 'urn': 'urn:cts:greekLit:tlg0062.tlg001.perseus-grc1',
         'sections': None, 'author': 'Plotinus', 'lang': 'Greek', 'cites': 24},

        {'name': 'De Interpretatione', 'urn': 'urn:cts:greekLit:tlg0086.tlg013.perseus-grc1',
         'sections': None, 'author': 'Aristotle', 'lang': 'Greek', 'cites': 18},

        {'name': 'De Stoicorum Repugnantiis', 'urn': 'urn:cts:greekLit:tlg0007.tlg096.perseus-grc1',
         'sections': None, 'author': 'Plutarch', 'lang': 'Greek', 'cites': 16},

        {'name': 'Eudemian Ethics', 'urn': 'urn:cts:greekLit:tlg0086.tlg011.perseus-grc1',
         'sections': None, 'author': 'Aristotle', 'lang': 'Greek', 'cites': 15},

        {'name': 'Academica', 'urn': 'urn:cts:latinLit:phi0474.phi006.perseus-lat1',
         'sections': range(1, 148), 'author': 'Cicero', 'lang': 'Latin', 'cites': 13},

        {'name': 'Discourses', 'urn': 'urn:cts:greekLit:tlg0557.tlg001.perseus-grc1',
         'sections': None, 'author': 'Epictetus', 'lang': 'Greek', 'cites': 13},
    ]

    for work in works:
        try:
            retriever.retrieve_work(
                work_name=work['name'],
                urn_base=work['urn'],
                sections=work['sections'],
                author=work['author'],
                language=work['lang']
            )
            time.sleep(1)  # Pause between works
        except KeyboardInterrupt:
            print("\n\n‚ö†Ô∏è  Interrupted by user")
            break
        except Exception as e:
            print(f"\n‚úó ERROR: {e}\n")
            continue

    retriever.print_stats()

    print("\nüéâ Batch retrieval complete!")
    print(f"Check: {retriever.output_dir}/")

if __name__ == '__main__':
    main()
